{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21c95c-0cc9-44e7-b081-376800a6d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207ca8c-dfb7-434a-ab45-034f12669564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 50)\n",
    "import numpy as np\n",
    "import math\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\n",
    "import gc\n",
    "import math\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from catboost import Pool, CatBoostRanker\n",
    "import xgboost as xgb\n",
    "from numba import njit\n",
    "from numba import prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6967a-c2ab-4963-b9ca-f51549cac0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/greenwolf/lightgbm-fast-recall-20から引用\n",
    "@njit(parallel=True) # the only difference from previous version\n",
    "def numba_recall20(preds, targets, groups):\n",
    "    total = 0\n",
    "    nonempty = 0\n",
    "    group_starts = np.cumsum(groups)\n",
    "\n",
    "    # for group_id in range(len(groups)):\n",
    "    for group_id in prange(len(groups)): # changed range to prange\n",
    "        group_end = group_starts[group_id]\n",
    "        group_start = group_end - groups[group_id]\n",
    "        ranks = np.argsort(preds[group_start:group_end])[::-1]\n",
    "        hits = 0\n",
    "        for i in range(min(len(ranks), 20)):\n",
    "            hits += targets[group_start + ranks[i]]\n",
    "\n",
    "        actual = min(20, targets[group_start:group_end].sum())\n",
    "        if actual > 0:\n",
    "            total += hits / actual\n",
    "            nonempty += 1\n",
    "\n",
    "    return total / nonempty\n",
    "\n",
    "\n",
    "def lgb_numba_recall(preds, lgb_dataset):\n",
    "    metric = numba_recall20(preds, lgb_dataset.label, lgb_dataset.group)\n",
    "    return 'numba_recall@20', metric, True\n",
    "\n",
    "def xgb_numba_recall(preds, xgb_dataset):\n",
    "    metric = numba_recall20(preds, xgb_dataset.get_label(), xgb_dataset.get_group())\n",
    "    return 'numba_recall@20', metric\n",
    "\n",
    "def create_dataset(size: int) -> lgb.Dataset:\n",
    "    data = np.random.normal(size=(size, 10))\n",
    "    target = np.random.randint(0, 2, size)\n",
    "    groups = np.ones(size // 40, dtype=np.int32) * 40 # groups of 40\n",
    "    return lgb.Dataset(data, target, group=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53d04b-6955-47d8-9442-df2ba8175e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1_000_000\n",
    "eval_dataset = create_dataset(size)\n",
    "lgb_numba_recall(np.zeros(size), eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d670dd2-910b-4e12-9a18-f81797c75ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(pred_df, valid_session, action_type):\n",
    "    \n",
    "    sub = pred_df.filter(pl.col('session_type').str.contains(action_type))\n",
    "    sub = (\n",
    "        sub.with_columns([\n",
    "            pl.col('session_type').str.split('_').arr.first().cast(pl.Int32).alias('session'),\n",
    "            pl.col('labels').str.split(' ')\n",
    "        ])\n",
    "        .drop('session_type')\n",
    "    )\n",
    "    test_labels = pl.read_parquet('input/otto_train_and_test_data_for_local_validation/test_labels.parquet')\n",
    "    test_labels = test_labels.filter((pl.col('type')==f'{action_type}s')&(pl.col('session').is_in(valid_session.to_list())))\n",
    "    test_labels = (\n",
    "        test_labels.with_columns([\n",
    "            pl.col('ground_truth').arr.lengths().clip(0, 20).alias('gt_count'),\n",
    "            pl.col('session').cast(pl.Int32)\n",
    "        ])\n",
    "    )\n",
    "    test_labels = test_labels.join(sub, on='session', how='left')\n",
    "    hits = test_labels.apply(lambda df:len(set(df[2]).intersection(set(map(int, df[4])))))\n",
    "    recall = hits['apply'].sum() / test_labels['gt_count'].sum()\n",
    "    \n",
    "    print(f'{action_type} recall =',recall)\n",
    "    \n",
    "    return recall\n",
    "\n",
    "def output_feature_importance(ranker, feature):\n",
    "    for i in range(len(ranker.feature_importances_)):\n",
    "        print(\n",
    "            np.array(feature)[np.argsort(ranker.feature_importances_, )][::-1][i],\n",
    "            np.sort(ranker.feature_importances_)[::-1][i]\n",
    "        )\n",
    "\n",
    "def down_sampling(df, nega_posi_ratio):\n",
    "    sampled_negative = df.filter(pl.col('gt')==0).sample(nega_posi_ratio*df['gt'].sum(), seed=0)\n",
    "    return pl.concat([df.filter(pl.col('gt')==1), sampled_negative])\n",
    "\n",
    "def infer_gbranker(test, gbranker, feature, nsplit):\n",
    "    chunk_size = math.ceil(len(test) / nsplit)\n",
    "    chunks = []\n",
    "    for i in range(nsplit):\n",
    "        start = i * chunk_size\n",
    "        end = min((i+1) * chunk_size, len(test))\n",
    "        score = gbranker.predict(test[start:end][feature].to_pandas(), num_iteration=gbranker.best_iteration)\n",
    "        # score = gbranker.predict(xgb.DMatrix(test[start:end][feature].to_numpy()), iteration_range=(0, gbranker.best_iteration))\n",
    "        chunks.append(test[start:end][['session', 'aid']].with_column(pl.Series(score).alias('score').cast(pl.Float32)))\n",
    "    return pl.concat(chunks) \n",
    "\n",
    "def cross_validation(df, action_type, feature, params):\n",
    "    num_gt = df.groupby('session', maintain_order=True).agg(pl.col('gt').sum().cast(pl.UInt16))\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    recalls = []\n",
    "    best_iter = []\n",
    "    for fold, (train_index, valid_index) in enumerate(skf.split(num_gt['session'], num_gt['gt'])):\n",
    "        train_session = num_gt['session'][train_index]\n",
    "        valid_session = num_gt['session'][valid_index]\n",
    "        train = df.filter(pl.col('session').is_in(train_session))\n",
    "        valid = df.filter(pl.col('session').is_in(valid_session))\n",
    "        \n",
    "        nega_posi_ratio = {'click':10, 'cart':20, 'order':20}\n",
    "        \n",
    "        train = down_sampling(train, nega_posi_ratio[action_type])\n",
    "        \n",
    "        session_lengths_train = train.groupby('session').count().sort('session')['count'].to_numpy()\n",
    "        train = train.sort('session')\n",
    "        \n",
    "        session_lengths_valid = valid.groupby('session').count().sort('session')['count'].to_numpy()\n",
    "        valid = valid.sort('session')\n",
    "        \n",
    "        # train_pool = Pool(data=train[feature].to_numpy(), label=train['gt'].to_numpy(), group_id=train['session'].to_numpy())\n",
    "        # valid_pool = Pool(data=valid[feature].to_numpy(), label=valid['gt'].to_numpy(), group_id=valid['session'].to_numpy())\n",
    "        # ranker = CatBoostRanker(**params)\n",
    "        # ranker.fit(\n",
    "        #     train_pool,\n",
    "        #     eval_set=valid_pool,\n",
    "        #     early_stopping_rounds=50\n",
    "        # )\n",
    "\n",
    "#         train_dataset = xgb.DMatrix(data=train[feature].to_numpy(), label=train['gt'].to_numpy(), group=session_lengths_train)\n",
    "#         eval_dataset = xgb.DMatrix(data=valid[feature].to_numpy(), label=valid['gt'].to_numpy(), group=session_lengths_valid)\n",
    "        \n",
    "#         ranker = xgb.train(\n",
    "#             params,\n",
    "#             train_dataset,\n",
    "#             evals=[(eval_dataset, 'eval_dataset')],\n",
    "#             custom_metric=xgb_numba_recall,\n",
    "#             num_boost_round=10000,\n",
    "#             early_stopping_rounds=50,\n",
    "#             verbose_eval=10,\n",
    "#             maximize=True\n",
    "#         )\n",
    "        \n",
    "        train_dataset = lgb.Dataset(train[feature].to_numpy(), train['gt'].to_numpy(), group=session_lengths_train)\n",
    "        eval_dataset = lgb.Dataset(valid[feature].to_numpy(), valid['gt'].to_numpy(), group=session_lengths_valid)\n",
    "        \n",
    "        ranker = lgb.train(\n",
    "            params,\n",
    "            train_dataset,\n",
    "            valid_sets=eval_dataset,\n",
    "            feval=lgb_numba_recall,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False), lgb.log_evaluation(10)]\n",
    "            # callbacks=[lgb.log_evaluation(10)]\n",
    "        )      \n",
    "        print(f'best iteration = {ranker.best_iteration}')\n",
    "        best_iter.append(ranker.best_iteration)\n",
    "        \n",
    "        # if fold == 0:\n",
    "        #     output_feature_importance(ranker, feature)\n",
    "        \n",
    "        valid = infer_gbranker(valid, ranker, feature, 10)\n",
    "        \n",
    "        pred = valid.sort(['session', 'score'], reverse=[False, True]).groupby('session', maintain_order=True).agg(pl.col('aid').head(20))\n",
    "        pred = pred.with_columns([pl.col('session').apply(lambda x:str(x)+f'_{action_type}s'), pl.col('aid').apply(lambda x:' '.join(map(str, x.to_list())))])\n",
    "        pred = pred.rename({'session':'session_type', 'aid':'labels'})\n",
    "        \n",
    "        recalls.append(compute_recall(pred, valid_session, action_type))\n",
    "        \n",
    "        del train, valid\n",
    "        gc.collect()\n",
    "    \n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_best_iter = np.mean(best_iter)\n",
    "    print(f'mean {action_type} recall = {mean_recall}')\n",
    "    print(f'mean {action_type} best iteration = {mean_best_iter}')\n",
    "    return mean_recall\n",
    "    \n",
    "def compute_score():\n",
    "    \n",
    "    recall = {}\n",
    "    # max_depth = {'click':7, 'cart':6, 'order':7}\n",
    "    for action_type in ['order', 'cart', 'click']:\n",
    "        train = pl.read_parquet(f'train_{action_type}.parquet')\n",
    "\n",
    "        feature = train.drop([\n",
    "                        'session', \n",
    "                        'aid', \n",
    "                        'gt',\n",
    "                        'user_order'\n",
    "                    ]).columns    \n",
    "\n",
    "        params = {\n",
    "            'boosting_type':'gbdt',\n",
    "            'objective':'lambdarank',\n",
    "            'metric':'\"None\"',\n",
    "            'learning_rate':0.05,\n",
    "            'num_boost_round':10000,\n",
    "            # 'max_depth':max_depth[action_type],\n",
    "            'max_depth':6,\n",
    "            'num_leaves':32,\n",
    "            'min_child_samples':471,\n",
    "            'reg_alpha':0.06786952863490345,\n",
    "            'reg_lambda':0.0013212485115586014,\n",
    "            'random_state':500,\n",
    "            'bagging_fraction': 0.877462547767822,\n",
    "            'feature_fraction': 0.37792222260319913,\n",
    "            'bagging_freq': 1\n",
    "        }\n",
    "    \n",
    "        # params = {\n",
    "        #     'loss_function':'YetiRank',\n",
    "        #     'iterations':10000,\n",
    "        #     'learning_rate':0.1,\n",
    "        #     'random_seed':100,\n",
    "        #     'eval_metric':CatBoostEvalMetric()\n",
    "        # }\n",
    "    \n",
    "        # params = {\n",
    "        #     'booster':'gbtree',\n",
    "        #     'objective':'rank:pairwise',\n",
    "        #     'random_state':100,\n",
    "        #     'learning_rate':0.1\n",
    "        # }\n",
    "\n",
    "        recall[action_type] = cross_validation(train, action_type, feature, params)\n",
    "        \n",
    "        del train\n",
    "        gc.collect()\n",
    "\n",
    "    weight = {'click': 0.10, 'cart': 0.30, 'order': 0.60}\n",
    "    score = recall['click']*weight['click'] + recall['cart']*weight['cart'] + recall['order']*weight['order']\n",
    "    print('Overall Recall =',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e59666-f436-4cd0-a14b-b77b0f7314dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class objective(object):\n",
    "    def __init__(self, df, action_type, feature):\n",
    "        self.df = df\n",
    "        self.action_type = action_type\n",
    "        self.feature = feature\n",
    "    def __call__(self, trial):\n",
    "        \n",
    "        max_depth = trial.suggest_int('max_depth', 5, 9)\n",
    "        num_leaves_max = 2**max_depth\n",
    "        num_leaves_upper = int(0.8*num_leaves_max)\n",
    "        num_leaves_lower = int(0.5*num_leaves_max)\n",
    "        num_leaves = trial.suggest_int('num_leaves', num_leaves_lower, num_leaves_upper)\n",
    "        min_child_samples = trial.suggest_int('min_child_samples', 1, 1000)\n",
    "        reg_alpha = trial.suggest_loguniform('reg_alpha', 0.00001, 0.1)\n",
    "        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.00001, 0.1)\n",
    "        bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 0.9)\n",
    "        feature_fraction = trial.suggest_float('feature_fraction', 0.1, 0.9)\n",
    "        bagging_freq = trial.suggest_int('bagging_freq', 0, 50)\n",
    "        params = {\n",
    "            'boosting_type':'gbdt',\n",
    "            'objective':'lambdarank',\n",
    "            'metric':'\"None\"',\n",
    "            'n_estimators':10000,\n",
    "            'learning_rate':0.1,\n",
    "            'random_state':500,\n",
    "            'max_depth':max_depth,\n",
    "            'num_leaves':num_leaves,\n",
    "            'min_child_samples':min_child_samples,\n",
    "            'reg_alpha':reg_alpha,\n",
    "            'reg_lambda':reg_lambda,\n",
    "            'bagging_fraction':bagging_fraction,\n",
    "            'bagging_freq':bagging_freq,\n",
    "            'feature_fraction':feature_fraction\n",
    "        }\n",
    "        return cross_validation(self.df, self.action_type, self.feature, params)\n",
    "    \n",
    "def optimize_parameter(action_type):\n",
    "    \n",
    "    train = pl.read_parquet(f'train_{action_type}.parquet')\n",
    "    feature = train.drop([\n",
    "                'session',\n",
    "                'aid',\n",
    "                'gt',\n",
    "                'user_order'\n",
    "                ]).columns\n",
    "    objective_func = objective(train, action_type, feature)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_func, n_trials=50)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4c02e-69cb-4181-a002-247f957d303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
